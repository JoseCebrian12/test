{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING EXP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# codificaciones = pd.read_excel(\n",
    "#     r\"cce/src/Data/Codificaciones.xlsx\", sheet_name=\"codificaciones\"\n",
    "# )\n",
    "codificaciones = pd.read_excel(\n",
    "    r\"/home/cnvdba/cce/src_dev/Data/Codificaciones.xlsx\", sheet_name=\"codificaciones\"\n",
    ")\n",
    "codificaciones.Code = codificaciones.Code.str.strip()\n",
    "rename_columns = {\n",
    "    \"creation_date\": \"creationDate\",\n",
    "    \"creation_time\": \"creationTime\",\n",
    "    \"creditor_participant_code\": \"creditorParticipantCode\",\n",
    "    \"debtor_participant_code\": \"debtorParticipantCode\",\n",
    "    \"debtor_type_person\": \"debtorTypeOfPerson\",\n",
    "    \"transaction_type\": \"transactionType\",\n",
    "    \"debtor_id\": \"debtorId\",\n",
    "    \"debtor_id_code\": \"debtorIdCode\",\n",
    "    \"creditor_cci\": \"creditorCCI\",\n",
    "    \"creditor_credit_card\": \"creditorCreditCard\",\n",
    "    \"reason_code\": \"reasonCode\",\n",
    "    \"response_code\": \"responseCode\",\n",
    "    \"creditor_id\": \"creditorId\",\n",
    "    \"creditor_id_code\": \"creditorIdCode\",\n",
    "}\n",
    "\n",
    "dict_column_list = {\n",
    "    \"debtorParticipantCode\": \"participants\",\n",
    "    \"creditorParticipantCode\": \"participants\",\n",
    "    \"transactionType\": \"transaction_type\",\n",
    "    \"currency\": \"currency\",\n",
    "    \"channel\": \"channel\",\n",
    "    \"responseCode\": \"response_code\",\n",
    "    \"reasonCode\": \"reason_code\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "_driver = \"PostgreSQL ANSI(x64)\"\n",
    "_server = \"localhost\" #\"10.201.4.25\" \n",
    "_database = \"coemcas\"\n",
    "_username = \"coemcas\"\n",
    "_password = \"C03$CMa5$2099\"\n",
    "_port = \"5432\"\n",
    "PREDICTION_PIPELINE = False\n",
    "NEW_VARIABLES_FLAG = True\n",
    "def get_database_conection():\n",
    "    connection = psycopg2.connect(\n",
    "        host=_server,\n",
    "        database=_database,\n",
    "        user=_username,\n",
    "        password=_password,\n",
    "        port=_port\n",
    "    )\n",
    "    return connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def data_ingestion_from_database():\n",
    "    #TODO: REVERT SQL QUERY\n",
    "    #Given the first unrun batch it finds, it retrieves all the transactions from the last 7 days (excluding the unrun batch) \n",
    "    if PREDICTION_PIPELINE:\n",
    "        #TODO: temporarily remove duplicate rows (by pk)\n",
    "        sql = \"\"\"\n",
    "            WITH run_id_to_process AS (\n",
    "                SELECT r.run_id, r.run_date, r.run_end_datetime\n",
    "                FROM fraud_model_run r\n",
    "                WHERE r.run_start_datetime = (\n",
    "                    SELECT MIN(r2.run_start_datetime)\n",
    "                    FROM fraud_model_run r2\n",
    "                    WHERE COALESCE(r2.run_process_status, 0) = 0\n",
    "                )\n",
    "            ),\n",
    "            debtor_ids AS (\n",
    "                SELECT DISTINCT m.debtor_id, r.run_id AS current_run_id, r.run_date AS current_run_date, r.run_end_datetime\n",
    "                FROM run_id_to_process r\n",
    "                INNER JOIN stage_ipf_message m ON r.run_id = m.run_id\n",
    "            )\n",
    "            SELECT DISTINCT ON (m.pk) m.*, d.current_run_id\n",
    "            FROM stage_ipf_message m \n",
    "            INNER JOIN debtor_ids d ON m.debtor_id = d.debtor_id\n",
    "            WHERE m.run_id = d.current_run_id\n",
    "            OR (\n",
    "                m.run_id != d.current_run_id\n",
    "                AND m.creation_date BETWEEN d.current_run_date - interval '90 days' AND d.current_run_date\n",
    "                AND (\n",
    "                    m.creation_date < d.current_run_date \n",
    "                    OR (m.creation_date = d.current_run_date AND m.creation_time <= d.run_end_datetime::time)\n",
    "                )\n",
    "            );\n",
    "        \"\"\"\n",
    "    else:\n",
    "        #TODO: delete \"limit 1000\" and change \"rn <= 20000\" to \"rn <= 200000\"\n",
    "        sql = \"\"\"\n",
    "            with debtor_ids as (\n",
    "                select debtor_id, current_creation_date\n",
    "                from (\n",
    "                    select \n",
    "                        debtor_id, \n",
    "                        current_creation_date,\n",
    "                        row_number() over (partition by current_creation_date order by random()) as rn\n",
    "                    from (\n",
    "                        select \n",
    "                            distinct m.debtor_id, \n",
    "                            m.creation_date as current_creation_date\n",
    "                        from stage_ipf_message m\n",
    "                        where m.creation_date between '2024-11-12' and '2024-11-18' limit 5000\n",
    "                    ) distinct_pairs\n",
    "                ) numbered_pairs\n",
    "                where rn <= 5000\n",
    "            ),\n",
    "            filtered_rows as (\n",
    "                select \n",
    "                    m.*, \n",
    "                    row_number() over (partition by m.pk) as row_num\n",
    "                from stage_ipf_message m\n",
    "                inner join debtor_ids d on m.debtor_id = d.debtor_id\n",
    "                where m.creation_date between d.current_creation_date - interval '90 days' and d.current_creation_date\n",
    "            )\n",
    "            select *\n",
    "            from filtered_rows\n",
    "            where row_num = 1;\n",
    "        \"\"\"\n",
    "\n",
    "    connection = None\n",
    "    # Establish the database connection\n",
    "    connection = get_database_conection()\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    print(f\"EXEC - Started query to get AV_consolidado rows at {datetime.datetime.now()}\")\n",
    "    cursor.execute(sql)\n",
    "    print(f\"EXEC - Ended query (cursor.execute) to get AV_consolidado rows at {datetime.datetime.now()}\")\n",
    "    # Obtener los nombres de las columnas\n",
    "    column_names = [desc[0] for desc in cursor.description]\n",
    "    # Obtener los resultados como una lista de listas\n",
    "    results = cursor.fetchall()\n",
    "    print(f\"EXEC - Ended query (cursor.fetchall) to get AV_consolidado rows at {datetime.datetime.now()}\")\n",
    "    cursor.close()\n",
    "    if connection is not None:\n",
    "        connection.close()\n",
    "    # Convertir los resultados en un DataFrame\n",
    "    AV_consolidado = pd.DataFrame(results, columns=column_names)\n",
    "\n",
    "    return AV_consolidado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXEC - Started query to get AV_consolidado rows at 2024-12-06 11:39:06.736065\n",
      "EXEC - Ended query (cursor.execute) to get AV_consolidado rows at 2024-12-06 11:39:29.774171\n",
      "EXEC - Ended query (cursor.fetchall) to get AV_consolidado rows at 2024-12-06 11:39:30.149335\n"
     ]
    }
   ],
   "source": [
    "AV_consolidado = data_ingestion_from_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if PREDICTION_PIPELINE:\n",
    "    max_run_id = AV_consolidado.iloc[0][\"current_run_id\"]\n",
    "else:\n",
    "    max_run_id = \"XXX\"\n",
    "drop_cols_av_cons = (\n",
    "    ['log_timestamp_replica', 'last_modified', 'current_run_id'] \n",
    "    if PREDICTION_PIPELINE \n",
    "    else ['log_timestamp_replica', 'last_modified', 'row_num']\n",
    ")\n",
    "AV_consolidado = AV_consolidado.drop(columns=drop_cols_av_cons)\n",
    "# AV_consolidado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75225, 22)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AV_consolidado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2971"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AV_consolidado['debtor_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        000686890\n",
       "1        000686890\n",
       "2        000552090\n",
       "3         00053716\n",
       "4        000127755\n",
       "           ...    \n",
       "75220    000015151\n",
       "75221    000214941\n",
       "75222    000073850\n",
       "75223    000172904\n",
       "75224    000650032\n",
       "Name: debtor_id, Length: 75225, dtype: object"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AV_consolidado['debtor_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49739       000690531\n",
       "47828    000003216715\n",
       "62984    000001650417\n",
       "37300        00062778\n",
       "60604       000195099\n",
       "41231       000651781\n",
       "70593       000157905\n",
       "65501       000591541\n",
       "43520       000195838\n",
       "37378       000178449\n",
       "57047       000068449\n",
       "72496       000342702\n",
       "1165        000097686\n",
       "64896       000656413\n",
       "8959        000636200\n",
       "59642    000002769732\n",
       "57657       000436499\n",
       "42370    000004440827\n",
       "38204       000212655\n",
       "51345       000060375\n",
       "19764    000006414322\n",
       "73987        00037654\n",
       "20347        00019756\n",
       "42263       000138196\n",
       "30291       000067574\n",
       "54054       000469125\n",
       "58332       000189106\n",
       "70691        00059267\n",
       "6010        000579478\n",
       "25883       000461761\n",
       "72785        00039385\n",
       "4591        000474871\n",
       "69529    000005532032\n",
       "52720    000003378575\n",
       "52518       000248056\n",
       "44393       000490477\n",
       "56902       000174974\n",
       "42702       000270701\n",
       "74778       000095161\n",
       "71758       000539140\n",
       "72035    000001900746\n",
       "17049        00011031\n",
       "43957        00018792\n",
       "68779        00018339\n",
       "48744       000373365\n",
       "69333    000003333053\n",
       "32134       000645250\n",
       "52812       000370994\n",
       "32168    000002327730\n",
       "68715    000002964066\n",
       "Name: debtor_id, dtype: object"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AV_consolidado['debtor_id'].sample(n=50, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Crear lista negra DUMMY\n",
    "\n",
    "# Define a function to generate a list of unique strings\n",
    "def generate_unique_number_strings(count, length):\n",
    "    return [\"\".join(random.sample(\"0123456789\", length)) for _ in range(count)]\n",
    "def generate_random_black_lists(df_col, count, rs_i):\n",
    "    return df_col.sample(n=count, random_state=42+rs_i).tolist()\n",
    "\n",
    "# Initialize participant list and black_list dictionaries\n",
    "participant_list = [\n",
    "    \"0002\", \"0003\", \"0007\", \"0009\", \"0011\", \"0018\", \"0023\", \"0035\", \n",
    "    \"0038\", \"0043\", \"0049\", \"0053\", \"0054\", \"0055\", \"0058\", \"0094\", \n",
    "    \"0096\", \"0801\", \"0802\", \"0803\", \"0805\", \"0806\", \"0808\", \"0809\"\n",
    "]\n",
    "black_list = {\"debtor\": {}, \"creditor\": {}}\n",
    "\n",
    "# Populate black_list with random unique number strings\n",
    "i = 0\n",
    "\n",
    "for participant in participant_list:\n",
    "    for bl in black_list:\n",
    "        # random_list = generate_unique_number_strings(10, 10)  # Generate 10 strings of 10 unique numbers\n",
    "        random_list = generate_random_black_lists(AV_consolidado[\"debtor_id\"], 10, i) if bl == \"debtor\" else generate_random_black_lists(AV_consolidado[\"creditor_id\"], 50, i) \n",
    "        black_list[bl][participant] = random_list\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pk', 'debtor_id', 'creditor_cci', 'creation_date', 'creation_time',\n",
       "       'channel', 'currency', 'creditor_participant_code',\n",
       "       'debtor_participant_code', 'debtor_type_person', 'transaction_type',\n",
       "       'debtor_id_code', 'creditor_credit_card', 'reason_code',\n",
       "       'response_code', 'creditor_id', 'creditor_id_code', 'message_id',\n",
       "       'trace', 'instruction_id', 'run_id', 'same_customer_flag',\n",
       "       'personeria_debtor', 'personeria_creditor', 'transaction_amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear personeria origen y destino DUMMY\n",
    "unique_debtors = AV_consolidado['debtor_id'].unique()\n",
    "unique_creditors = AV_consolidado['creditor_id'].unique()\n",
    "\n",
    "personeria_options = ['Natural', 'Juridica']\n",
    "new_columns = [\"personeria_debtor_natural\", \"personeria_creditor_natural\"]\n",
    "debtor_personeria_mapping = {debtor: np.random.choice(personeria_options) for debtor in unique_debtors}\n",
    "creditor_personeria_mapping = {creditor: np.random.choice(personeria_options) for creditor in unique_creditors}\n",
    "\n",
    "AV_consolidado['personeria_debtor'] = AV_consolidado['debtor_id'].map(debtor_personeria_mapping)\n",
    "AV_consolidado['personeria_creditor'] = AV_consolidado['creditor_id'].map(creditor_personeria_mapping)\n",
    "\n",
    "# Crear monto de transaccion DUMMY\n",
    "\n",
    "np.random.seed(0)  # Optional: for reproducibility\n",
    "AV_consolidado['transaction_amount'] = np.random.uniform(100, 1000, size=len(AV_consolidado))\n",
    "AV_consolidado.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Juridica\n",
       "1        Juridica\n",
       "2        Juridica\n",
       "3         Natural\n",
       "4        Juridica\n",
       "           ...   \n",
       "75220    Juridica\n",
       "75221    Juridica\n",
       "75222     Natural\n",
       "75223     Natural\n",
       "75224    Juridica\n",
       "Name: personeria_debtor, Length: 75225, dtype: object"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AV_consolidado.personeria_debtor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debtorParticipantCode\n",
      "creditorParticipantCode\n",
      "transactionType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2940361/4162895485.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  AV_consolidado[column_to_decode].fillna(\"\", inplace=True)\n",
      "/tmp/ipykernel_2940361/4162895485.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  AV_consolidado[column_to_decode].fillna(\"\", inplace=True)\n",
      "/tmp/ipykernel_2940361/4162895485.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  AV_consolidado[column_to_decode].fillna(\"\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currency\n",
      "channel\n",
      "responseCode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2940361/4162895485.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  AV_consolidado[column_to_decode].fillna(\"\", inplace=True)\n",
      "/tmp/ipykernel_2940361/4162895485.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  AV_consolidado[column_to_decode].fillna(\"\", inplace=True)\n",
      "/tmp/ipykernel_2940361/4162895485.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  AV_consolidado[column_to_decode].fillna(\"\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasonCode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2940361/4162895485.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  AV_consolidado[column_to_decode].fillna(\"\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#NUEVA\n",
    "# Renombrar columnas in-place\n",
    "AV_consolidado.rename(columns=rename_columns, inplace=True)\n",
    "# start = time.time()\n",
    "for column_to_decode, value in dict_column_list.items():\n",
    "    print(column_to_decode)\n",
    "    # Filtrar codificaciones relevantes\n",
    "    codificaciones_stage = codificaciones[codificaciones['List'] == value][[\"Code\", \"Value\"]]\n",
    "    codificaciones_dict = codificaciones_stage.set_index('Code')['Value'].to_dict()\n",
    "\n",
    "    # Rellenar valores nulos en la columna a decodificar\n",
    "    AV_consolidado[column_to_decode].fillna(\"\", inplace=True)\n",
    "\n",
    "    # Realizar el merge de forma más eficiente\n",
    "    AV_consolidado['temp'] = AV_consolidado[column_to_decode].map(codificaciones_dict)\n",
    "\n",
    "    if column_to_decode not in [\"reasonCode\"]:\n",
    "        AV_consolidado['temp'] = AV_consolidado['temp'].fillna(\"invalid\")\n",
    " \n",
    "    # Insertar la columna mapeada en el lugar adecuado\n",
    "    AV_consolidado[column_to_decode] = AV_consolidado['temp']\n",
    "    AV_consolidado.drop('temp', axis=1, inplace=True)\n",
    "# Renombrar columnas finales in-place\n",
    "AV_consolidado.rename(\n",
    "    columns={\n",
    "        \"debtorParticipantCode\": \"debtorParticipant\",\n",
    "        \"creditorParticipantCode\": \"creditorParticipant\",\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "# end = time.time()\n",
    "# print(\"TOT TIME\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2024-08-14\n",
       "1     2024-08-15\n",
       "2     2024-08-16\n",
       "3     2024-08-17\n",
       "4     2024-08-18\n",
       "         ...    \n",
       "92    2024-11-14\n",
       "93    2024-11-15\n",
       "94    2024-11-16\n",
       "95    2024-11-17\n",
       "96    2024-11-18\n",
       "Name: creationDate, Length: 97, dtype: object"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AV_consolidado.creationDate.drop_duplicates().sort_values().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "AV_consolidado[\"flag_invalid\"] = (AV_consolidado.astype(str).apply(lambda x: x == \"invalid\").any(axis=1)).astype(\"uint8\")\n",
    "AV_consolidado_original_values_set_stage = AV_consolidado.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "AV_consolidado.reset_index(drop=True, inplace=True)\n",
    "rows_dropped = (AV_consolidado_original_values_set_stage.shape[0] - AV_consolidado.shape[0])\n",
    "if rows_dropped > 0:\n",
    "    print(f\"{rows_dropped} rows dropped because any value was invalid\")\n",
    "AV_consolidado.drop([\"flag_invalid\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "vars_to_discard = [\n",
    "    \"pk\",\n",
    "    \"reasonCode\",\n",
    "    \"run_id\",\n",
    "    \"trace\",\n",
    "    \"instruction_id\",\n",
    "    \"message_id\",\n",
    "]  # 1\n",
    "\n",
    "vars_to_feature_engineer = [\"creationDate\", \"creationTime\"]  # 2\n",
    "vars_to_ohe = [\n",
    "    \"debtorTypeOfPerson\",\n",
    "    \"debtorParticipant\",\n",
    "    \"creditorParticipant\",\n",
    "    \"transactionType\",\n",
    "    \"currency\",\n",
    "    \"channel\",\n",
    "    \"responseCode\",\n",
    "    \"personeria_debtor\",\n",
    "    \"personeria_creditor\",\n",
    "]  # 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FRECUENCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#FRECUENCIA\n",
    "def create_frequency_features(df, new_cols, freq_days = [1, 7, 30, 90]):\n",
    "    df = df.sort_values(by=[\"debtorId\",\"creationDate\",\"creationTime\"]) #.dropna().copy()\n",
    "    # df[\"creation_date_temp2\"] = df[\"creation_date_temp\"]\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.set_index('creation_date_temp2', inplace=True)\n",
    "    result_df = pd.DataFrame(index=df.index)\n",
    "    day_intervals = df[\"day_interval\"].unique()\n",
    "    for di in day_intervals:\n",
    "        df[f'di_is_{di}'] = (df['day_interval'] == di).astype(int)\n",
    "    for days in freq_days:\n",
    "        vals = [0] * len(df)\n",
    "        for di in day_intervals:\n",
    "            di_counts = (df.groupby('debtorId')[f'di_is_{di}']\n",
    "                        .rolling(window=f'{days}d')\n",
    "                        .sum()\n",
    "                        .reset_index(level=0, drop=True))\n",
    "\n",
    "            new_col = f\"f{di}_{days}d\"\n",
    "            res = di_counts / days\n",
    "            result_df[new_col] = res\n",
    "            vals = [x + y for x, y in zip(vals, res)]\n",
    "            new_cols.append(new_col)\n",
    "        new_col = f\"f{days}d\"\n",
    "        result_df[new_col] = vals\n",
    "        new_cols.append(new_col)\n",
    "        ################################### OG\n",
    "        # result = (df.groupby('debtorId')\n",
    "        #                 .rolling(window=f'{days}d', on='creation_date_temp2')\n",
    "        #                 .creation_date_temp2\n",
    "        #                 .count())  # Rolling count without resetting index\n",
    "        # result = result.reset_index(level=0, drop=True)\n",
    "        # new_col = f\"f{days}d\"\n",
    "        # result_df[new_col] = result.values / days\n",
    "        # new_cols.append(new_col)\n",
    "        ##################################\n",
    "    # print(result_df)\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "    for di in day_intervals:\n",
    "        df.drop(columns=f'di_is_{di}', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = pd.concat([df, result_df], axis=1)\n",
    "    return df, new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CANTIDAD DE OPERACIONES DEL CLIENTE POR DIA Y POR CANAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# CANTIDAD DE OPERACIONES DEL CLIENTE POR DIA Y POR CANAL\n",
    "def rolling_total_count(group, days):\n",
    "    return group.rolling(window=f'{days}D').count()\n",
    "\n",
    "def create_frequency_per_channel(df, new_cols, freq_days=[1, 7, 30, 90]):\n",
    "    df = df.sort_values(by=[\"debtorId\", \"creationDate\", \"creationTime\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.set_index('creation_date_temp', inplace=True)\n",
    "    df[\"clean_channel\"] = df[\"channel\"].astype(str).apply(unidecode).str.replace(\" \", \"_\", regex=\"False\").str.lower()\n",
    "    channel_types = df[\"clean_channel\"].unique()\n",
    "    for channel in channel_types:\n",
    "        df[f'channel_is_{channel}'] = (df['clean_channel'] == channel).astype(int)\n",
    "    for days in freq_days:\n",
    "        # Contar el total de eventos en la ventana de días\n",
    "        total_counts = (\n",
    "            df.groupby('debtorId')['clean_channel']\n",
    "            .apply(lambda group: rolling_total_count(group, days))\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "        for channel in channel_types:\n",
    "            # Contar eventos por canal en la ventana de días\n",
    "            channel_counts = (\n",
    "                df.groupby('debtorId')[f'channel_is_{channel}']\n",
    "                .rolling(window=f'{days}D')\n",
    "                .sum()\n",
    "                .reset_index(level=0, drop=True)\n",
    "            )\n",
    "\n",
    "            # Calcular la proporción para ese canal y ventana de tiempo\n",
    "            new_col = f'prop_{channel}_{days}d'\n",
    "            df[new_col] = channel_counts / total_counts\n",
    "            new_cols.append(new_col)\n",
    "    for channel in channel_types:\n",
    "        df.drop(columns=f'channel_is_{channel}', inplace=True)\n",
    "    df.drop(columns=[\"clean_channel\"], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df, new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNI DESTINO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# DNI DESTINO \n",
    "def create_frequency_interaction_creditor_id(df, new_cols, freq_days = [1, 7, 30, 90]):\n",
    "    df[\"creditorId\"] = df[\"creditorId\"].fillna(\"00000000\")\n",
    "    df = df.sort_values(by=[\"debtorId\",\"creditorId\", \"creationDate\",\"creationTime\"]) #.dropna().copy()\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    result_df = pd.DataFrame(index=df.index)\n",
    "    for days in freq_days:\n",
    "        # result = (df.groupby(['debtorId', 'creditorId'])\n",
    "        #                     .rolling(window=f'90d', on='creation_date_temp')\n",
    "        #                     .creation_date_temp\n",
    "        #                     .count().reset_index(drop=True))\n",
    "        result = (df.groupby(['debtorId', 'creditorId'])\n",
    "                .rolling(window=f'{days}d', on='creation_date_temp')\n",
    "                .creation_date_temp\n",
    "                .count())\n",
    "        result = result.reset_index(level=[0], drop=True)\n",
    "        new_col = f\"f{days}d_to_creditor\"\n",
    "        result_df[new_col] = result.values / days\n",
    "        new_cols.append(new_col)\n",
    "    # print(result_df)\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "    df = pd.concat([df, result_df], axis=1)\n",
    "    return df, new_cols   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUENTAS CON ABONOS DE DIFERENTES ORIGENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#CUENTAS CON ABONOS DE DIFERENTES ORIGENES\n",
    "def create_unique_debtors_per_creditor(df, new_cols, freq_days = [1, 7, 30, 90]):    \n",
    "    # Sort by CreditorCCI, debtorId, and transaction date to ensure chronological order\n",
    "    df[\"creditorId\"] = df[\"creditorId\"].fillna(\"00000000\")\n",
    "    df = df.sort_values(by=[\"creditorId\", \"creationDate\",\"creationTime\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Create an empty DataFrame to store the results\n",
    "    result_df = pd.DataFrame(index=df.index)\n",
    "\n",
    "    # Use a rolling window per creditor to get unique debtorIds\n",
    "    # result = (df.groupby('creditorId')\n",
    "    #             .rolling(window=f'{window_days}d', on='creation_date_temp')\n",
    "    #             .apply(lambda x: x['debtorId'].unique(), raw=False)\n",
    "    #             )\n",
    "    df[\"hash_id\"] = pd.factorize(df[\"debtorId\"])[0]\n",
    "    # Crear ambos diccionarios en un solo bucle\n",
    "    # hash_in, hash_out = {}, {}\n",
    "    # for _, row in df.iterrows():\n",
    "    #     debtor_id = row[\"debtorId\"]\n",
    "    #     hash_id = row[\"hash_id\"]\n",
    "    #     hash_in[debtor_id] = hash_id\n",
    "    #     hash_out[hash_id] = debtor_id\n",
    "    for days in freq_days:\n",
    "        print(days)\n",
    "        # result = df.groupby('creditorId').apply(lambda x: x.rolling(window=f'{days}d', on='creation_date_temp').hash_id.apply(lambda y: y.nunique() ))\n",
    "        result = (df.groupby('creditorId').rolling(window=f'{days}d', on='creation_date_temp')['hash_id'].apply(lambda y: y.nunique()))\n",
    "        # Reset the index to avoid issues with multi-indexing\n",
    "        # result = result.reset_index(level=[0], drop=True)\n",
    "        result = result.reset_index(level=[0], drop=True).values\n",
    "\n",
    "        # Add the result to the original DataFrame\n",
    "        new_col = f\"unique_debtors_past_{days}d\"\n",
    "        result_df[new_col] = result\n",
    "        new_cols.append(new_col)\n",
    "        # Concatenate with the original DataFrame\n",
    "    df = pd.concat([df, result_df], axis=1)\n",
    "    df.drop(columns=[\"hash_id\"], inplace=True)\n",
    "    \n",
    "    return df, new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROPORCION DE MONTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def amount_proportion(df, new_cols, freq_days = [1, 7, 30, 90]):\n",
    "    df = df.sort_values(by=[\"debtorId\", \"creationDate\",\"creationTime\"]) #.dropna().copy()\n",
    "    df = df.reset_index(drop=True)\n",
    "    result_df = pd.DataFrame(index=df.index)\n",
    "    for days in freq_days:\n",
    "        result = (df.groupby(['debtorId'])\n",
    "                .rolling(window=f'{days}d', on='creation_date_temp')\n",
    "                .transaction_amount\n",
    "                .sum())\n",
    "        result = result.reset_index(level=[0], drop=True)\n",
    "        new_col = f\"prop{days}d_amount\"\n",
    "        result_df[new_col] = df.transaction_amount / result.values\n",
    "        new_cols.append(new_col)\n",
    "    # print(result_df)\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "    df = pd.concat([df, result_df], axis=1)\n",
    "    return df, new_cols   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def categorize_day_interval(hour):\n",
    "    \"\"\"\n",
    "    Categorize the given hour into specific day intervals.\n",
    "\n",
    "    Args:\n",
    "        hour (int or str): The hour to be categorized. It can be an integer or a string representation of an integer.\n",
    "\n",
    "    Returns:\n",
    "        str: The category corresponding to the input hour.\n",
    "\n",
    "    \"\"\"\n",
    "    # Zero-padding if needed\n",
    "    hour = str(hour).zfill(6)  \n",
    "    # Extract the hour part\n",
    "    hour = int(hour[:2])  \n",
    "    # Define day interval categories\n",
    "    if hour >= 0 and hour < 6:\n",
    "        return 'early morning'\n",
    "    elif hour >= 6 and hour < 12:\n",
    "        return 'morning'\n",
    "    elif hour >= 12 and hour < 18:\n",
    "        return 'afternoon'\n",
    "    else:  # hour >= 18 or hour < 24\n",
    "        return 'evening'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "AV_consolidado[\"day_interval\"] = AV_consolidado[\"creationTime\"].apply(categorize_day_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "AV_consolidado[\"creation_date_temp\"] = pd.to_datetime(AV_consolidado[\"creationDate\"])\n",
    "temp = AV_consolidado.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first\n",
      "second\n",
      "1\n",
      "7\n",
      "30\n",
      "90\n",
      "third\n",
      "fourth\n",
      "fifth\n"
     ]
    }
   ],
   "source": [
    "#NEW VARIABLES\n",
    "if NEW_VARIABLES_FLAG:\n",
    "    AV_consolidado[\"creation_date_temp2\"] = pd.to_datetime(AV_consolidado[\"creationDate\"])\n",
    "    AV_consolidado[\"creation_date_temp\"] = pd.to_datetime(AV_consolidado[\"creationDate\"])\n",
    "    #in this exact order, to only create \"creation_date_temp\" once\n",
    "    AV_consolidado, new_columns = create_frequency_features(AV_consolidado, new_columns)\n",
    "    print(\"first\")\n",
    "    AV_consolidado, new_columns = create_frequency_interaction_creditor_id(AV_consolidado, new_columns)\n",
    "    print(\"second\")\n",
    "    AV_consolidado, new_columns = create_unique_debtors_per_creditor(AV_consolidado, new_columns)\n",
    "    print(\"third\")\n",
    "    AV_consolidado, new_columns = amount_proportion(AV_consolidado, new_columns)\n",
    "    print(\"fourth\")\n",
    "    AV_consolidado, new_columns = create_frequency_per_channel(AV_consolidado, new_columns)\n",
    "    print(\"fifth\")\n",
    "    AV_consolidado_original_values_set_stage = AV_consolidado.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# NEW\n",
    "# 1 vars_to_discard\n",
    "AV_consolidado = AV_consolidado.drop(columns=vars_to_discard)\n",
    "\n",
    "# 2 vars_to_feature_engineer\n",
    "AV_consolidado = AV_consolidado.rename(\n",
    "    columns={\n",
    "        \"creationDate\": \"creationDate_stage\",\n",
    "        \"creationTime\": \"creationTime_stage\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Conversión de fechas y horas\n",
    "AV_consolidado[\"creationDate_stage\"] = pd.to_datetime(AV_consolidado[\"creationDate_stage\"])\n",
    "AV_consolidado[\"creationTime_stage\"] = AV_consolidado[\"creationTime_stage\"].astype(str).str.replace(\":\", \"\", regex=False)\n",
    "AV_consolidado[\"creationTime\"] = pd.to_datetime(AV_consolidado[\"creationTime_stage\"], format=\"%H%M%S\").dt.time\n",
    "\n",
    "# Creación de características cíclicas\n",
    "def create_cyclic_features(df):\n",
    "    df[\"hourSin\"] = np.sin(2 * np.pi * df[\"creationTime\"].apply(lambda x: x.hour) / 24.0)\n",
    "    df[\"hourCos\"] = np.cos(2 * np.pi * df[\"creationTime\"].apply(lambda x: x.hour) / 24.0)\n",
    "    df[\"dayOfYearSin\"] = np.sin(2 * np.pi * df[\"creationDate_stage\"].dt.dayofyear / 365.0)\n",
    "    df[\"dayOfYearCos\"] = np.cos(2 * np.pi * df[\"creationDate_stage\"].dt.dayofyear / 365.0)\n",
    "    df[\"dayOfMonthSin\"] = np.sin(2 * np.pi * df[\"creationDate_stage\"].dt.day / 31.0)\n",
    "    df[\"dayOfMonthCos\"] = np.cos(2 * np.pi * df[\"creationDate_stage\"].dt.day / 31.0)\n",
    "    df[\"dayOfWeekSin\"] = np.sin(2 * np.pi * df[\"creationDate_stage\"].dt.weekday / 7.0)\n",
    "    df[\"dayOfWeekCos\"] = np.cos(2 * np.pi * df[\"creationDate_stage\"].dt.weekday / 7.0)\n",
    "    df[\"monthSin\"] = np.sin(2 * np.pi * df[\"creationDate_stage\"].dt.month / 12.0)\n",
    "    df[\"monthCos\"] = np.cos(2 * np.pi * df[\"creationDate_stage\"].dt.month / 12.0)\n",
    "    return df\n",
    "\n",
    "\n",
    "vars_to_feature_engineer = [\"creationTime\"]  # 2\n",
    "\n",
    "AV_consolidado = create_cyclic_features(AV_consolidado)\n",
    "\n",
    "# Eliminación de columnas intermedias\n",
    "AV_consolidado = AV_consolidado.drop(columns=[\"creationDate_stage\", \"creationTime_stage\", *vars_to_feature_engineer])\n",
    "\n",
    "# 3 vars_to_ohe\n",
    "AV_consolidado_3_stage = AV_consolidado.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Cambiar formato a \"snake_case\" sin tildes\n",
    "for column in vars_to_ohe:\n",
    "    AV_consolidado_3_stage[column] = (\n",
    "        AV_consolidado_3_stage[column]\n",
    "        .astype(str)\n",
    "        .apply(unidecode)\n",
    "        .str.replace(\" \", \"_\", regex=False)\n",
    "        .str.lower()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['debtorTypeOfPerson',\n",
       " 'debtorParticipant',\n",
       " 'creditorParticipant',\n",
       " 'transactionType',\n",
       " 'currency',\n",
       " 'channel',\n",
       " 'responseCode',\n",
       " 'personeria_debtor',\n",
       " 'personeria_creditor']"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_to_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cnvdba/miniconda3/envs/mvp1_shap/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse=False,\n",
       "              sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, handle_unknown=&#x27;ignore&#x27;, sparse=False,\n",
       "              sparse_output=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(drop='first', handle_unknown='ignore', sparse=False,\n",
       "              sparse_output=False)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if PREDICTION_PIPELINE:\n",
    "    ohe = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "else:\n",
    "    ohe = OneHotEncoder(sparse=False, handle_unknown=\"ignore\", drop=\"first\")\n",
    "ohe.fit(AV_consolidado_3_stage[vars_to_ohe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['none'], dtype=object),\n",
       " array(['alfin_banco_s.a.', 'banbif', 'banco_de_la_nacion',\n",
       "        'banco_falabella', 'banco_pichincha', 'banco_ripley', 'bbva',\n",
       "        'bcp', 'caja_arequipa', 'caja_cusco', 'caja_huancayo', 'caja_ica',\n",
       "        'caja_piura', 'caja_trujillo', 'comercio',\n",
       "        'crediscotia_financiera', 'financiera_efectiva', 'financiera_oh',\n",
       "        'gnb', 'interbank', 'invalid', 'mi_banco', 'scotiabank'],\n",
       "       dtype=object),\n",
       " array(['alfin_banco_s.a.', 'banbif', 'banco_de_la_nacion',\n",
       "        'banco_falabella', 'banco_pichincha', 'banco_ripley', 'bbva',\n",
       "        'bcp', 'caja_arequipa', 'caja_cusco', 'caja_huancayo', 'caja_ica',\n",
       "        'caja_piura', 'caja_trujillo', 'citibank', 'comercio',\n",
       "        'crediscotia_financiera', 'financiera_efectiva', 'financiera_oh',\n",
       "        'gnb', 'interbank', 'invalid', 'mi_banco', 'scotiabank'],\n",
       "       dtype=object),\n",
       " array(['ordinary_transfer', 'payments_to_account_card'], dtype=object),\n",
       " array(['dollars', 'soles'], dtype=object),\n",
       " array(['atm', 'banca_movil', 'invalid', 'web'], dtype=object),\n",
       " array(['accepted', 'rejected'], dtype=object),\n",
       " array(['juridica', 'natural'], dtype=object),\n",
       " array(['juridica', 'natural'], dtype=object)]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "AV_consolidado_3_ohe_stage = pd.DataFrame(ohe.transform(AV_consolidado_3_stage[vars_to_ohe]),columns=ohe.get_feature_names_out(vars_to_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "AV_consolidado = pd.concat([AV_consolidado_3_stage.drop(vars_to_ohe, axis=1), AV_consolidado_3_ohe_stage],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debtorId</th>\n",
       "      <th>creditorCCI</th>\n",
       "      <th>channel</th>\n",
       "      <th>currency</th>\n",
       "      <th>creditorParticipant</th>\n",
       "      <th>debtorParticipant</th>\n",
       "      <th>debtorTypeOfPerson</th>\n",
       "      <th>transactionType</th>\n",
       "      <th>debtorIdCode</th>\n",
       "      <th>creditorCreditCard</th>\n",
       "      <th>...</th>\n",
       "      <th>hourSin</th>\n",
       "      <th>hourCos</th>\n",
       "      <th>dayOfYearSin</th>\n",
       "      <th>dayOfYearCos</th>\n",
       "      <th>dayOfMonthSin</th>\n",
       "      <th>dayOfMonthCos</th>\n",
       "      <th>dayOfWeekSin</th>\n",
       "      <th>dayOfWeekCos</th>\n",
       "      <th>monthSin</th>\n",
       "      <th>monthCos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000018298</td>\n",
       "      <td>00253519137531001137</td>\n",
       "      <td>invalid</td>\n",
       "      <td>soles</td>\n",
       "      <td>bcp</td>\n",
       "      <td>banco_de_la_nacion</td>\n",
       "      <td>none</td>\n",
       "      <td>ordinary_transfer</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.785650</td>\n",
       "      <td>-0.618671</td>\n",
       "      <td>-0.968077</td>\n",
       "      <td>-0.250653</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000018298</td>\n",
       "      <td>00253519410805205636</td>\n",
       "      <td>invalid</td>\n",
       "      <td>soles</td>\n",
       "      <td>bcp</td>\n",
       "      <td>banco_de_la_nacion</td>\n",
       "      <td>none</td>\n",
       "      <td>ordinary_transfer</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.796183</td>\n",
       "      <td>-0.605056</td>\n",
       "      <td>-0.998717</td>\n",
       "      <td>-0.050649</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000018298</td>\n",
       "      <td>00253519218341307731</td>\n",
       "      <td>invalid</td>\n",
       "      <td>soles</td>\n",
       "      <td>bcp</td>\n",
       "      <td>banco_de_la_nacion</td>\n",
       "      <td>none</td>\n",
       "      <td>ordinary_transfer</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.816538</td>\n",
       "      <td>-0.577292</td>\n",
       "      <td>-0.937752</td>\n",
       "      <td>0.347305</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000018298</td>\n",
       "      <td>00253519699567404535</td>\n",
       "      <td>invalid</td>\n",
       "      <td>soles</td>\n",
       "      <td>bcp</td>\n",
       "      <td>banco_de_la_nacion</td>\n",
       "      <td>none</td>\n",
       "      <td>ordinary_transfer</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.826354</td>\n",
       "      <td>-0.563151</td>\n",
       "      <td>-0.848644</td>\n",
       "      <td>0.528964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000018298</td>\n",
       "      <td>00253519410805205636</td>\n",
       "      <td>invalid</td>\n",
       "      <td>soles</td>\n",
       "      <td>bcp</td>\n",
       "      <td>banco_de_la_nacion</td>\n",
       "      <td>none</td>\n",
       "      <td>ordinary_transfer</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.826354</td>\n",
       "      <td>-0.563151</td>\n",
       "      <td>-0.848644</td>\n",
       "      <td>0.528964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       debtorId           creditorCCI  channel currency creditorParticipant  \\\n",
       "0  000000018298  00253519137531001137  invalid    soles                 bcp   \n",
       "1  000000018298  00253519410805205636  invalid    soles                 bcp   \n",
       "2  000000018298  00253519218341307731  invalid    soles                 bcp   \n",
       "3  000000018298  00253519699567404535  invalid    soles                 bcp   \n",
       "4  000000018298  00253519410805205636  invalid    soles                 bcp   \n",
       "\n",
       "    debtorParticipant debtorTypeOfPerson    transactionType debtorIdCode  \\\n",
       "0  banco_de_la_nacion               none  ordinary_transfer            4   \n",
       "1  banco_de_la_nacion               none  ordinary_transfer            4   \n",
       "2  banco_de_la_nacion               none  ordinary_transfer            4   \n",
       "3  banco_de_la_nacion               none  ordinary_transfer            4   \n",
       "4  banco_de_la_nacion               none  ordinary_transfer            4   \n",
       "\n",
       "  creditorCreditCard  ...       hourSin   hourCos dayOfYearSin dayOfYearCos  \\\n",
       "0               None  ... -7.071068e-01 -0.707107    -0.785650    -0.618671   \n",
       "1               None  ... -2.588190e-01 -0.965926    -0.796183    -0.605056   \n",
       "2               None  ...  1.224647e-16 -1.000000    -0.816538    -0.577292   \n",
       "3               None  ...  9.659258e-01 -0.258819    -0.826354    -0.563151   \n",
       "4               None  ...  1.224647e-16 -1.000000    -0.826354    -0.563151   \n",
       "\n",
       "  dayOfMonthSin dayOfMonthCos  dayOfWeekSin dayOfWeekCos  monthSin  monthCos  \n",
       "0     -0.968077     -0.250653      0.433884    -0.900969 -0.866025      -0.5  \n",
       "1     -0.998717     -0.050649     -0.433884    -0.900969 -0.866025      -0.5  \n",
       "2     -0.937752      0.347305     -0.781831     0.623490 -0.866025      -0.5  \n",
       "3     -0.848644      0.528964      0.000000     1.000000 -0.866025      -0.5  \n",
       "4     -0.848644      0.528964      0.000000     1.000000 -0.866025      -0.5  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AV_consolidado_3_stage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "AV_consolidado[AV_consolidado_3_ohe_stage.columns] = AV_consolidado[AV_consolidado_3_ohe_stage.columns].astype(\"uint8\")\n",
    "AV_consolidado_completed = pd.DataFrame()\n",
    "AV_consolidado_completed = pd.concat([AV_consolidado_completed, AV_consolidado], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "AV_consolidado_original = pd.DataFrame()\n",
    "AV_consolidado_original_stage = AV_consolidado.copy()\n",
    "AV_consolidado_original = pd.concat([AV_consolidado_original, AV_consolidado_original_stage],axis=0,ignore_index=True,)\n",
    "AV_consolidado_original_values_set = pd.DataFrame()\n",
    "AV_consolidado_original_values_set = pd.concat([AV_consolidado_original_values_set, AV_consolidado_original_values_set_stage],axis=0,ignore_index=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Fill nulls\n",
    "AV_consolidado_completed.fillna(value=0, inplace=True)\n",
    "\n",
    "# Set all binary to uint8 (except the ones that are uint8 already)\n",
    "id_columns = [\n",
    "    \"debtorId\",\n",
    "    \"debtorIdCode\",\n",
    "    \"creditorCCI\",\n",
    "    \"creditorCreditCard\",\n",
    "    \"creditorId\",\n",
    "    \"creditorIdCode\",\n",
    "]\n",
    "\n",
    "excluded_columns = (\n",
    "    [\n",
    "        \"hourSin\",\n",
    "        \"hourCos\",\n",
    "        \"dayOfYearSin\",\n",
    "        \"dayOfYearCos\",\n",
    "        \"dayOfMonthSin\",\n",
    "        \"dayOfMonthCos\",\n",
    "        \"dayOfWeekSin\",\n",
    "        \"dayOfWeekCos\",\n",
    "        \"monthSin\",\n",
    "        \"monthCos\",\n",
    "        \"same_customer_flag\",\n",
    "        \"transaction_amount\",\n",
    "        \"day_interval\"\n",
    "    ]\n",
    "    + AV_consolidado_completed.select_dtypes(include=\"uint8\").columns.to_list()\n",
    "    + id_columns \n",
    ")\n",
    "if NEW_VARIABLES_FLAG:\n",
    "    excluded_columns +=  new_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BINARY []\n"
     ]
    }
   ],
   "source": [
    "# Get a list of column names excluding 'excluded_columns' and id columns\n",
    "binary_columns = list(set(AV_consolidado_completed.columns).difference(excluded_columns))\n",
    "print(\"BINARY\", binary_columns)\n",
    "\n",
    "# Convert the binary columns to uint8\n",
    "AV_consolidado_completed[binary_columns] = AV_consolidado_completed[binary_columns].astype(\"uint8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# # Export AV_consolidado_completed\n",
    "# output_file_path = \"cce_ipf_message_feature_engineering.pickle\"\n",
    "# AV_consolidado_completed.to_pickle(output_file_path)\n",
    "\n",
    "# # Export AV_consolidado_original\n",
    "# output_file_path = \"cce_ipf_message_original.pickle\"\n",
    "# AV_consolidado_original.to_pickle(output_file_path)\n",
    "\n",
    "# # Export AV_consolidado_original_values_set\n",
    "# output_file_path = \"cce_ipf_message_original_values_set.pickle\"\n",
    "# AV_consolidado_original_values_set.to_pickle(output_file_path)\n",
    "# print(\"end of execution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75225, 74)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AV_consolidado_original_values_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75225, 120)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AV_consolidado_completed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING RATIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def generate_combinations(input_list):\n",
    "    \"\"\"\n",
    "    Generate all possible combinations of elements from the given input list.\n",
    "\n",
    "    The function generates combinations by first including each element in a separate list,\n",
    "    and then combining two elements at a time to form new combinations.\n",
    "\n",
    "    Args:\n",
    "        input_list (list): The list of elements from which to generate combinations.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing all possible combinations of elements.\n",
    "    \"\"\"\n",
    "    \n",
    "    output_list = []\n",
    "\n",
    "    for i in range(len(input_list)):\n",
    "        # Add each element in a list of 1 item\n",
    "        output_list.append([input_list[i]])\n",
    "\n",
    "        for j in range(i + 1, len(input_list)):\n",
    "            # Add combinations of two elements\n",
    "            output_list.append([input_list[i], input_list[j]])\n",
    "\n",
    "    return output_list\n",
    "\n",
    "def categorize_hour(hour):\n",
    "    \"\"\"\n",
    "    Categorize the given hour into specific time intervals.\n",
    "\n",
    "    Args:\n",
    "        hour (int or str): The hour to be categorized. It can be an integer or a string representation of an integer.\n",
    "\n",
    "    Returns:\n",
    "        str: The category corresponding to the input hour.\n",
    "\n",
    "    \"\"\"\n",
    "    # Zero-padding if needed\n",
    "    hour = str(hour).zfill(6)  \n",
    "    # Extract the hour part\n",
    "    hour = int(hour[:2])  \n",
    "    # Define time interval categories\n",
    "    if hour >= 0 and hour < 3:\n",
    "        return '00 to 03'\n",
    "    elif hour >= 3 and hour < 6:\n",
    "        return '03 to 06'\n",
    "    elif hour >= 6 and hour < 9:\n",
    "        return '06 to 09'\n",
    "    elif hour >= 9 and hour < 12:\n",
    "        return '09 to 12'\n",
    "    elif hour >= 12 and hour < 15:\n",
    "        return '12 to 15'\n",
    "    elif hour >= 15 and hour < 18:\n",
    "        return '15 to 18'\n",
    "    elif hour >= 18 and hour < 21:\n",
    "        return '18 to 21'\n",
    "    else:  # hour >= 21 or hour < 24\n",
    "        return '21 to 00'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Define a list of columns to keep in the resulting DataFrame\n",
    "lista = [\n",
    "    \"debtorId\",\n",
    "    \"creditorCCI\",\n",
    "    \"run_id\",\n",
    "    \"creditorParticipant\",\n",
    "    \"currency\",\n",
    "    \"channel\",\n",
    "    \"responseCode\",\n",
    "    \"debtorParticipant\",\n",
    "    \"creationDate\",\n",
    "    \"creationTime\",\n",
    "    \"time_interval\",\n",
    "    \"Weekday\",\n",
    "]\n",
    "\n",
    "# Generate all possible combinations of columns to be used for ratio calculations\n",
    "\n",
    "input_list = [\n",
    "    \"creditorParticipant\",\n",
    "    \"currency\",\n",
    "    \"channel\",\n",
    "    \"responseCode\",\n",
    "    \"debtorParticipant\",\n",
    "    \"Weekday\",\n",
    "    \"time_interval\",\n",
    "    \"creditorCCI\",\n",
    "]\n",
    "\n",
    "if NEW_VARIABLES_FLAG:\n",
    "    lista += [\"creditorId\",\"personeria_creditor\"]\n",
    "    input_list += [\"creditorId\", \"personeria_creditor\"]\n",
    "\n",
    "output_list = generate_combinations(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#antes = 45 \n",
    "# dsps\n",
    "len(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "directory_path = \"\"\n",
    "# Define the filenames for feature engineering and original values set DataFrames\n",
    "file_name_feature_engineering = \"cce_ipf_message_feature_engineering.pickle\"\n",
    "file_name_original_values_set = \"cce_ipf_message_original_values_set.pickle\"\n",
    "\n",
    "# Build the file paths for the feature engineering and original values set DataFrames\n",
    "file_path_fe = os.path.join(directory_path, file_name_feature_engineering)\n",
    "file_path_o_vs = os.path.join(directory_path, file_name_original_values_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# # Export AV_consolidado_completed\n",
    "# output_file_path = \"cce_ipf_message_feature_engineering.pickle\"\n",
    "# AV_consolidado_completed.to_pickle(output_file_path)\n",
    "\n",
    "# # Export AV_consolidado_original\n",
    "# output_file_path = \"cce_ipf_message_original.pickle\"\n",
    "# AV_consolidado_original.to_pickle(output_file_path)\n",
    "\n",
    "# # Export AV_consolidado_original_values_set\n",
    "# output_file_path = \"cce_ipf_message_original_values_set.pickle\"\n",
    "# AV_consolidado_original_values_set.to_pickle(output_file_path)\n",
    "# print(\"end of execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2940361/1182050474.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  AV_o_vs[\"creationDate\"] = pd.to_datetime(AV_o_vs[\"creationDate\"])\n"
     ]
    }
   ],
   "source": [
    "# Read the original values set DataFrame\n",
    "# AV_o_vs = pd.read_pickle(file_path_o_vs)\n",
    "AV_o_vs = AV_consolidado_original_values_set\n",
    "# Filter and preprocess the original values set DataFrame\n",
    "AV_o_vs = AV_o_vs[AV_o_vs[\"transactionType\"] == \"Ordinary Transfer\"]\n",
    "# AV_o_vs = AV_o_vs[AV_o_vs['debtorParticipant'].isin(code) | AV_o_vs['creditorParticipant'].isin(code)]\n",
    "AV_o_vs[\"creationDate\"] = pd.to_datetime(AV_o_vs[\"creationDate\"])\n",
    "df = AV_o_vs.copy()\n",
    "df[\"Weekday\"] = df[\"creationDate\"].apply(lambda x: x.weekday()).astype(object)\n",
    "df[\"time_interval\"] = df[\"creationTime\"].apply(categorize_hour)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75225"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AV_consolidado_original_values_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AV_consolidado_original_values_set[AV_consolidado_original_values_set[\"transactionType\"] != \"Ordinary Transfer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def Ratio(dd1, output_list, lista, days_back):  # revisar la fecha\n",
    "    \"\"\"\n",
    "    Calculate ratios based on cumulative counts for specified columns in the input DataFrame.\n",
    "\n",
    "    Args:\n",
    "        dd1 (pandas.DataFrame): The input DataFrame containing the data.\n",
    "        output_list (list): A list of lists, where each inner list represents a combination of columns for which ratios\n",
    "                            are to be calculated based on cumulative counts. The columns in each combination should be\n",
    "                            present in the DataFrame dd1.\n",
    "        lista (list): A list of column names from the DataFrame dd1 that will be used to extract data.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the calculated ratios for each combination specified in output_list.\n",
    "    \"\"\"\n",
    "    creditor = [\"debtorId\"]\n",
    "    dd2_completed_list = []\n",
    "\n",
    "    total_days = dd1.creationDate.drop_duplicates().sort_values().reset_index(drop=True)\n",
    "    if PREDICTION_PIPELINE:\n",
    "        training_days = [total_days.max()]\n",
    "    else:\n",
    "        training_days = total_days[total_days >= '2024-11-12'].reset_index(drop=True)\n",
    "\n",
    "    for i, _day in enumerate(training_days):\n",
    "        print(f\"Processing day {i+1} of {len(training_days)}: {_day}\")\n",
    "        dd2 = dd1[\n",
    "            (dd1.creationDate <= _day) & \n",
    "            (dd1.creationDate >= _day - pd.Timedelta(days=90))\n",
    "        ][lista].sort_values(by=[\"debtorId\", \"creationDate\", \"creationTime\"]).dropna().copy()\n",
    "        \n",
    "        dd2[\"count_cci\"] = dd2.groupby([\"debtorId\"]).cumcount() + 1\n",
    "        \n",
    "        new_columns = {}\n",
    "        for i in output_list:\n",
    "            column_prefix = '_'.join(map(str, i))\n",
    "            new_columns[f\"{column_prefix}_cumcount\"] = dd2.groupby(creditor + i).cumcount() + 1\n",
    "            new_columns[f\"{column_prefix}_ratio\"] = (\n",
    "                new_columns[f\"{column_prefix}_cumcount\"] / dd2[\"count_cci\"]\n",
    "            )\n",
    "\n",
    "        # Merge all new columns at once\n",
    "        dd2 = pd.concat([dd2, pd.DataFrame(new_columns, index=dd2.index)], axis=1)\n",
    "\n",
    "        if PREDICTION_PIPELINE:\n",
    "            dd2 = dd2[dd2.run_id == max(dd2.run_id)]\n",
    "        else:\n",
    "            dd2 = dd2[dd2.creationDate == _day]\n",
    "\n",
    "        print(\"SIZE DD2 (after filtering)\", days_back, dd2.shape)\n",
    "        dd2_completed_list.append(dd2)\n",
    "\n",
    "    # Combine all processed DataFrames\n",
    "    dd2_completed = pd.concat(dd2_completed_list, axis=0, ignore_index=False)\n",
    "    return dd2_completed.filter(like=\"ratio\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing day 1 of 7: 2024-11-12 00:00:00\n",
      "SIZE DD2 (after filtering) 90 (1244, 125)\n",
      "Processing day 2 of 7: 2024-11-13 00:00:00\n",
      "SIZE DD2 (after filtering) 90 (1269, 125)\n",
      "Processing day 3 of 7: 2024-11-14 00:00:00\n",
      "SIZE DD2 (after filtering) 90 (1282, 125)\n",
      "Processing day 4 of 7: 2024-11-15 00:00:00\n",
      "SIZE DD2 (after filtering) 90 (1340, 125)\n",
      "Processing day 5 of 7: 2024-11-16 00:00:00\n",
      "SIZE DD2 (after filtering) 90 (1180, 125)\n",
      "Processing day 6 of 7: 2024-11-17 00:00:00\n",
      "SIZE DD2 (after filtering) 90 (792, 125)\n",
      "Processing day 7 of 7: 2024-11-18 00:00:00\n",
      "SIZE DD2 (after filtering) 90 (1430, 125)\n",
      "(8537, 55)\n",
      "(8537, 55)\n"
     ]
    }
   ],
   "source": [
    "# Calculate ratios based on cumulative counts for specified columns\n",
    "df[\"creditorId\"] = df[\"creditorId\"].fillna(\"00000000\")\n",
    "ratios_df = Ratio(df, output_list, lista, 90)\n",
    "print(ratios_df.shape)\n",
    "ratios_df.dropna(inplace=True)\n",
    "print(ratios_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Read the feature engineering DataFrame\n",
    "# AV_fe = pd.read_pickle(file_path_fe)\n",
    "AV_fe = AV_consolidado_completed\n",
    "AV_fe['in_black_debtor'] = AV_fe['debtorId'].apply(lambda x: any(x in bl for bl in black_list['debtor'].values()))\n",
    "AV_fe['in_black_creditor'] = AV_fe['debtorId'].apply(lambda x: any(x in bl for bl in black_list['creditor'].values()))\n",
    "AV_fe = AV_fe.drop([\"debtorIdCode\", \"creditorCreditCard\", \"creditorId\", \"creditorIdCode\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Merge the calculated ratios DataFrame and the feature engineering DataFrame\n",
    "final = pd.merge(ratios_df, AV_fe, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final 90 (8537, 173)\n",
      "final 90 black (1595, 173)\n",
      "final 90 clean (6942, 173)\n",
      "(6942, 173)\n"
     ]
    }
   ],
   "source": [
    "#TODO: later after training/predicting, like with same_customer_flag, add the rows back. but now, with score = 99.\n",
    "# if some rows have same_customer_flag = 'M' but either debtor or creditor are in any black list, that row has score = 99.\n",
    "\n",
    "final_black = final[final['in_black_debtor'] | final['in_black_creditor']]  # Rows where either in_origen or in_destino is True\n",
    "final_clean = final[~(final['in_black_debtor'] | final['in_black_creditor'])]  # Rows where both in_origen and in_destino are False\n",
    "\n",
    "print(\"final 90\", final.shape)\n",
    "print(\"final 90 black\", final_black.shape)\n",
    "print(\"final 90 clean\", final_clean.shape)\n",
    "final = final_clean\n",
    "print(final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "final_same = final[final[\"same_customer_flag\"] == 'M']\n",
    "final_diff = final[final[\"same_customer_flag\"] != 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final 90 (6942, 173)\n",
      "final 90 same (1431, 173)\n",
      "final 90 diff (5511, 173)\n",
      "(5511, 173)\n"
     ]
    }
   ],
   "source": [
    "print(\"final 90\", final.shape)\n",
    "print(\"final 90 same\", final_same.shape)\n",
    "print(\"final 90 diff\", final_diff.shape)\n",
    "final = final_diff\n",
    "print(final.shape)\n",
    "# Save the final DataFrame to a pickle file\n",
    "directory_path = ''\n",
    "# final.to_pickle(os.path.join(directory_path, \"df_output.pickle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AV_train shape: (5511, 173)\n",
      "dropped ['monthSin', 'monthCos', 'debtorParticipant_banco_ripley', 'debtorParticipant_caja_huancayo', 'debtorParticipant_financiera_efectiva', 'creditorParticipant_banco_ripley', 'creditorParticipant_caja_huancayo', 'creditorParticipant_citibank', 'transactionType_payments_to_account_card', 'in_black_debtor', 'in_black_creditor']\n",
      "(5511, 162)\n",
      "(5511, 162)\n"
     ]
    }
   ],
   "source": [
    "RS = 12494328\n",
    "train_data_file_name = \"df_output.pickle\"\n",
    "#AV_train = pd.read_pickle(train_data_file_name)\n",
    "AV_train = final.copy(deep=True)\n",
    "# print(\"nasss\", AV_train.isna().sum() / AV_train.shape[0])\n",
    "# print(AV_train)\n",
    "# Explore train data\n",
    "print(f\"AV_train shape: {AV_train.shape}\")\n",
    "# print(f\"AV_train columns: {AV_train.columns}\")\n",
    "# print(f\"creditorCCI únicos: {AV_train.creditorCCI.nunique()}\")\n",
    "# print(\"Top 10 creditor CCI con más operaciones AV:\")\n",
    "# print(AV_train.creditorCCI.value_counts().sort_values(ascending=False).head(10))\n",
    "AV_train_nunique = AV_train.nunique()\n",
    "cols_to_drop_unique_value = AV_train_nunique[AV_train_nunique == 1].index.to_list()\n",
    "# drop columns with unique value\n",
    "if len(cols_to_drop_unique_value) > 0:\n",
    "    print(\"dropped\", cols_to_drop_unique_value)\n",
    "    # print(cols_to_drop_unique_value.index)\n",
    "    AV_train.drop(cols_to_drop_unique_value, axis=1, inplace=True)\n",
    "print(AV_train.shape)\n",
    "AV_train.dropna(inplace=True)\n",
    "print(AV_train.shape)\n",
    "\n",
    "args_5 = {\"random_state\": RS, \"contamination\": 0.0196}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added as 0 debtorParticipant_citibank\n",
      "added as 0 debtorParticipant_banco_ripley\n",
      "added as 0 debtorParticipant_alfin_banco_s.a.\n",
      "added as 0 debtorParticipant_financiera_efectiva\n",
      "added as 0 debtorParticipant_caja_sullana\n",
      "added as 0 debtorParticipant_caja_huancayo\n",
      "added as 0 creditorParticipant_citibank\n",
      "added as 0 creditorParticipant_banco_ripley\n",
      "added as 0 creditorParticipant_alfin_banco_s.a.\n",
      "added as 0 creditorParticipant_caja_sullana\n",
      "added as 0 creditorParticipant_caja_huancayo\n",
      "added as 0 in_black_debtor\n",
      "added as 0 in_black_creditor\n",
      "dropping... same_customer_flag\n",
      "dropping... day_interval\n"
     ]
    }
   ],
   "source": [
    "variables = [\n",
    "    \"creditorParticipant_ratio\",\n",
    "    \"creditorParticipant_currency_ratio\",\n",
    "    \"creditorParticipant_channel_ratio\",\n",
    "    \"creditorParticipant_responseCode_ratio\",\n",
    "    \"creditorParticipant_debtorParticipant_ratio\",\n",
    "    \"creditorParticipant_Weekday_ratio\",\n",
    "    \"creditorParticipant_time_interval_ratio\",\n",
    "    \"creditorParticipant_creditorCCI_ratio\",\n",
    "    \"currency_ratio\",\n",
    "    \"currency_channel_ratio\",\n",
    "    \"currency_responseCode_ratio\",\n",
    "    \"currency_debtorParticipant_ratio\",\n",
    "    \"currency_Weekday_ratio\",\n",
    "    \"currency_time_interval_ratio\",\n",
    "    \"currency_creditorCCI_ratio\",\n",
    "    \"channel_ratio\",\n",
    "    \"channel_responseCode_ratio\",\n",
    "    \"channel_debtorParticipant_ratio\",\n",
    "    \"channel_Weekday_ratio\",\n",
    "    \"channel_time_interval_ratio\",\n",
    "    \"channel_creditorCCI_ratio\",\n",
    "    \"responseCode_ratio\",\n",
    "    \"responseCode_debtorParticipant_ratio\",\n",
    "    \"responseCode_Weekday_ratio\",\n",
    "    \"responseCode_time_interval_ratio\",\n",
    "    \"responseCode_creditorCCI_ratio\",\n",
    "    \"debtorParticipant_ratio\",\n",
    "    \"debtorParticipant_Weekday_ratio\",\n",
    "    \"debtorParticipant_time_interval_ratio\",\n",
    "    \"debtorParticipant_creditorCCI_ratio\",\n",
    "    \"Weekday_ratio\",\n",
    "    \"Weekday_time_interval_ratio\",\n",
    "    \"Weekday_creditorCCI_ratio\",\n",
    "    \"time_interval_ratio\",\n",
    "    \"time_interval_creditorCCI_ratio\",\n",
    "    \"creditorCCI_ratio\",\n",
    "    \"debtorId\",\n",
    "    \"creditorCCI\",\n",
    "    \"hourSin\",\n",
    "    \"hourCos\",\n",
    "    \"dayOfYearSin\",\n",
    "    \"dayOfYearCos\",\n",
    "    \"dayOfMonthSin\",\n",
    "    \"dayOfMonthCos\",\n",
    "    \"dayOfWeekSin\",\n",
    "    \"dayOfWeekCos\",\n",
    "    \"debtorParticipant_bcp\",\n",
    "    \"debtorParticipant_interbank\",\n",
    "    \"debtorParticipant_citibank\",\n",
    "    \"debtorParticipant_scotiabank\",\n",
    "    \"debtorParticipant_bbva\",\n",
    "    \"debtorParticipant_banco_de_la_nacion\",\n",
    "    \"debtorParticipant_comercio\",\n",
    "    \"debtorParticipant_banco_pichincha\",\n",
    "    \"debtorParticipant_banbif\",\n",
    "    \"debtorParticipant_crediscotia_financiera\",\n",
    "    \"debtorParticipant_mi_banco\",\n",
    "    \"debtorParticipant_gnb\",\n",
    "    \"debtorParticipant_banco_falabella\",\n",
    "    \"debtorParticipant_banco_ripley\",\n",
    "    \"debtorParticipant_alfin_banco_s.a.\",\n",
    "    \"debtorParticipant_financiera_oh\",\n",
    "    \"debtorParticipant_financiera_efectiva\",\n",
    "    \"debtorParticipant_caja_piura\",\n",
    "    \"debtorParticipant_caja_trujillo\",\n",
    "    \"debtorParticipant_caja_arequipa\",\n",
    "    \"debtorParticipant_caja_sullana\",\n",
    "    \"debtorParticipant_caja_cusco\",\n",
    "    \"debtorParticipant_caja_huancayo\",\n",
    "    \"debtorParticipant_caja_ica\",\n",
    "    \"debtorParticipant_invalid\",\n",
    "    \"creditorParticipant_bcp\",\n",
    "    \"creditorParticipant_interbank\",\n",
    "    \"creditorParticipant_citibank\",\n",
    "    \"creditorParticipant_scotiabank\",\n",
    "    \"creditorParticipant_bbva\",\n",
    "    \"creditorParticipant_banco_de_la_nacion\",\n",
    "    \"creditorParticipant_comercio\",\n",
    "    \"creditorParticipant_banco_pichincha\",\n",
    "    \"creditorParticipant_banbif\",\n",
    "    \"creditorParticipant_crediscotia_financiera\",\n",
    "    \"creditorParticipant_mi_banco\",\n",
    "    \"creditorParticipant_gnb\",\n",
    "    \"creditorParticipant_banco_falabella\",\n",
    "    \"creditorParticipant_banco_ripley\",\n",
    "    \"creditorParticipant_alfin_banco_s.a.\",\n",
    "    \"creditorParticipant_financiera_oh\",\n",
    "    \"creditorParticipant_financiera_efectiva\",\n",
    "    \"creditorParticipant_caja_piura\",\n",
    "    \"creditorParticipant_caja_trujillo\",\n",
    "    \"creditorParticipant_caja_arequipa\",\n",
    "    \"creditorParticipant_caja_sullana\",\n",
    "    \"creditorParticipant_caja_cusco\",\n",
    "    \"creditorParticipant_caja_huancayo\",\n",
    "    \"creditorParticipant_caja_ica\",\n",
    "    \"creditorParticipant_invalid\",\n",
    "    \"currency_soles\",\n",
    "    \"channel_banca_movil\",\n",
    "    \"channel_invalid\",\n",
    "    \"channel_web\",\n",
    "    \"responseCode_rejected\",\n",
    "]\n",
    "if NEW_VARIABLES_FLAG:\n",
    "    new_ratios = [\n",
    "        \"creditorParticipant_creditorId_ratio\",\n",
    "        \"currency_creditorId_ratio\",\n",
    "        \"channel_creditorId_ratio\",\n",
    "        \"responseCode_creditorId_ratio\",\n",
    "        \"debtorParticipant_creditorId_ratio\",\n",
    "        \"Weekday_creditorId_ratio\",\n",
    "        \"time_interval_creditorId_ratio\",\n",
    "        \"creditorCCI_creditorId_ratio\",\n",
    "        \"creditorId_ratio\",\n",
    "        #### personeria ratios\n",
    "        \"creditorParticipant_personeria_creditor_ratio\",\n",
    "        \"currency_personeria_creditor_ratio\",\n",
    "        \"channel_personeria_creditor_ratio\",\n",
    "        \"responseCode_personeria_creditor_ratio\",\n",
    "        \"debtorParticipant_personeria_creditor_ratio\",\n",
    "        \"Weekday_personeria_creditor_ratio\",\n",
    "        \"time_interval_personeria_creditor_ratio\",\n",
    "        \"creditorCCI_personeria_creditor_ratio\",\n",
    "        \"creditorId_personeria_creditor_ratio\",\n",
    "        \"personeria_creditor_ratio\",\n",
    "    ]\n",
    "    new_columns += [\"transaction_amount\", \"in_black_debtor\", \"in_black_creditor\"]\n",
    "    variables += new_columns + new_ratios\n",
    "\n",
    "for col in variables:\n",
    "    if col not in AV_train.columns:\n",
    "        print(\"added as 0\", col)\n",
    "        AV_train[col] = 0\n",
    "\n",
    "for x in AV_train.columns:\n",
    "    if x not in variables:\n",
    "        print(\"dropping...\", x)\n",
    "AV_train = AV_train[variables]\n",
    "# print(\"variables train\", AV_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# model function\n",
    "def fit_isolation_forest(input_data, args=None):\n",
    "    rs = args[\"random_state\"]\n",
    "    c = args[\"contamination\"]\n",
    "   \n",
    "    model = IsolationForest(random_state=rs, contamination=c, n_jobs=-1)\n",
    "    model.fit(input_data)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "id_cols = [\"debtorId\", \"creditorCCI\", \"same_customer_flag\", \"in_black_debtor\", \"in_black_creditor\"]\n",
    "cols_to_drop = [col for col in id_cols if col in AV_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "new_columns_dummy = [\n",
    "    \"personeria_debtor_natural\",\n",
    "    \"personeria_creditor_natural\",\n",
    "    \"fafternoon_1d\",\n",
    "    \"fmorning_1d\",\n",
    "    \"fevening_1d\",\n",
    "    \"fearly morning_1d\",\n",
    "    \"fafternoon_7d\",\n",
    "    \"fmorning_7d\",\n",
    "    \"fevening_7d\",\n",
    "    \"fearly morning_7d\",\n",
    "    \"fafternoon_30d\",\n",
    "    \"fmorning_30d\",\n",
    "    \"fevening_30d\",\n",
    "    \"fearly morning_30d\",\n",
    "    \"fafternoon_90d\",\n",
    "    \"fmorning_90d\",\n",
    "    \"fevening_90d\",\n",
    "    \"fearly morning_90d\",\n",
    "    \"prop1d_amount\",\n",
    "    \"prop7d_amount\",\n",
    "    \"prop30d_amount\",\n",
    "    \"prop90d_amount\",\n",
    "    \"transaction_amount\",\n",
    "    \"in_black_debtor\",\n",
    "    \"in_black_creditor\",\n",
    "]\n",
    "new_ratios_dummy = [\n",
    "    \"creditorParticipant_personeria_creditor_ratio\",\n",
    "    \"currency_personeria_creditor_ratio\",\n",
    "    \"channel_personeria_creditor_ratio\",\n",
    "    \"responseCode_personeria_creditor_ratio\",\n",
    "    \"debtorParticipant_personeria_creditor_ratio\",\n",
    "    \"Weekday_personeria_creditor_ratio\",\n",
    "    \"time_interval_personeria_creditor_ratio\",\n",
    "    \"creditorCCI_personeria_creditor_ratio\",\n",
    "    \"creditorId_personeria_creditor_ratio\",\n",
    "    \"personeria_creditor_ratio\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#drop id_cols(debtorId, creditorCCE, same_customer_flag)\n",
    "if_model_90_new_vars = fit_isolation_forest(AV_train.drop(cols_to_drop, axis=1).sort_index(axis=1,ascending=True), args_5)\n",
    "if_model_90_old_vars = fit_isolation_forest(AV_train.drop(cols_to_drop + new_columns_dummy + new_ratios_dummy, axis=1).sort_index(axis=1,ascending=True), args_5)\n",
    "output_directory_path = \"\"\n",
    "file_path_new_vars = os.path.join(output_directory_path, \"test_mvp_1_model_90_new_vars_221124.pickle\")\n",
    "file_path_old_vars = os.path.join(output_directory_path, \"test_mvp_1_model_90_old_vars_221124.pickle\")\n",
    "with open(file_path_new_vars, \"wb\") as handle:\n",
    "    pickle.dump(if_model_90_new_vars, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(file_path_old_vars, \"wb\") as handle:\n",
    "    pickle.dump(if_model_90_old_vars, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def load_model(file_path, file_name):\n",
    "    full_file_path = os.path.join(file_path, file_name)\n",
    "    with open(full_file_path, 'rb') as handle:\n",
    "        loaded_model = pickle.load(handle)\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "tot_mod = ['creditorParticipant_ratio', 'creditorParticipant_currency_ratio', 'creditorParticipant_channel_ratio', 'creditorParticipant_responseCode_ratio', 'creditorParticipant_debtorParticipant_ratio', 'creditorParticipant_Weekday_ratio', 'creditorParticipant_time_interval_ratio', 'creditorParticipant_creditorCCI_ratio', 'currency_ratio', 'currency_channel_ratio', 'currency_responseCode_ratio', 'currency_debtorParticipant_ratio', 'currency_Weekday_ratio', 'currency_time_interval_ratio', 'currency_creditorCCI_ratio', 'channel_ratio', 'channel_responseCode_ratio', 'channel_debtorParticipant_ratio', 'channel_Weekday_ratio', 'channel_time_interval_ratio', 'channel_creditorCCI_ratio', 'responseCode_ratio', 'responseCode_debtorParticipant_ratio', 'responseCode_Weekday_ratio', 'responseCode_time_interval_ratio', 'responseCode_creditorCCI_ratio', 'debtorParticipant_ratio', 'debtorParticipant_Weekday_ratio', 'debtorParticipant_time_interval_ratio', 'debtorParticipant_creditorCCI_ratio', 'Weekday_ratio', 'Weekday_time_interval_ratio', 'Weekday_creditorCCI_ratio', 'time_interval_ratio', 'time_interval_creditorCCI_ratio', 'creditorCCI_ratio', 'hourSin', 'hourCos', 'dayOfYearSin', 'dayOfYearCos', 'dayOfMonthSin', 'dayOfMonthCos', 'dayOfWeekSin', 'dayOfWeekCos', 'debtorParticipant_bcp', 'debtorParticipant_interbank', 'debtorParticipant_citibank', 'debtorParticipant_scotiabank', 'debtorParticipant_bbva', 'debtorParticipant_banco_de_la_nacion', 'debtorParticipant_comercio', 'debtorParticipant_banco_pichincha', 'debtorParticipant_banbif', 'debtorParticipant_crediscotia_financiera', 'debtorParticipant_mi_banco', 'debtorParticipant_gnb', 'debtorParticipant_banco_falabella', 'debtorParticipant_banco_ripley', 'debtorParticipant_alfin_banco_s.a.', 'debtorParticipant_financiera_oh', 'debtorParticipant_financiera_efectiva', 'debtorParticipant_caja_piura', 'debtorParticipant_caja_trujillo', 'debtorParticipant_caja_arequipa', 'debtorParticipant_caja_sullana', 'debtorParticipant_caja_cusco', 'debtorParticipant_caja_huancayo', 'debtorParticipant_caja_ica', 'debtorParticipant_invalid', 'creditorParticipant_bcp', 'creditorParticipant_interbank', 'creditorParticipant_citibank', 'creditorParticipant_scotiabank', 'creditorParticipant_bbva', 'creditorParticipant_banco_de_la_nacion', 'creditorParticipant_comercio', 'creditorParticipant_banco_pichincha', 'creditorParticipant_banbif', 'creditorParticipant_crediscotia_financiera', 'creditorParticipant_mi_banco', 'creditorParticipant_gnb', 'creditorParticipant_banco_falabella', 'creditorParticipant_banco_ripley', 'creditorParticipant_alfin_banco_s.a.', 'creditorParticipant_financiera_oh', 'creditorParticipant_financiera_efectiva', 'creditorParticipant_caja_piura', 'creditorParticipant_caja_trujillo', 'creditorParticipant_caja_arequipa', 'creditorParticipant_caja_sullana', 'creditorParticipant_caja_cusco', 'creditorParticipant_caja_huancayo', 'creditorParticipant_caja_ica', 'creditorParticipant_invalid', 'currency_soles', 'channel_banca_movil', 'channel_invalid', 'channel_web', 'responseCode_rejected', 'personeria_debtor_natural', 'personeria_creditor_natural', 'fafternoon_1d', 'fmorning_1d', 'fevening_1d', 'fearly morning_1d', 'f1d', 'fafternoon_7d', 'fmorning_7d', 'fevening_7d', 'fearly morning_7d', 'f7d', 'fafternoon_30d', 'fmorning_30d', 'fevening_30d', 'fearly morning_30d', 'f30d', 'fafternoon_90d', 'fmorning_90d', 'fevening_90d', 'fearly morning_90d', 'f90d', 'f1d_to_creditor', 'f7d_to_creditor', 'f30d_to_creditor', 'f90d_to_creditor', 'unique_debtors_past_1d', 'unique_debtors_past_7d', 'unique_debtors_past_30d', 'unique_debtors_past_90d', 'prop1d_amount', 'prop7d_amount', 'prop30d_amount', 'prop90d_amount', 'prop_invalid_1d', 'prop_banca_movil_1d', 'prop_web_1d', 'prop_atm_1d', 'prop_invalid_7d', 'prop_banca_movil_7d', 'prop_web_7d', 'prop_atm_7d', 'prop_invalid_30d', 'prop_banca_movil_30d', 'prop_web_30d', 'prop_atm_30d', 'prop_invalid_90d', 'prop_banca_movil_90d', 'prop_web_90d', 'prop_atm_90d', 'transaction_amount', 'creditorParticipant_creditorId_ratio', 'currency_creditorId_ratio', 'channel_creditorId_ratio', 'responseCode_creditorId_ratio', 'debtorParticipant_creditorId_ratio', 'Weekday_creditorId_ratio', 'time_interval_creditorId_ratio', 'creditorCCI_creditorId_ratio', 'creditorId_ratio', 'creditorParticipant_personeria_creditor_ratio', 'currency_personeria_creditor_ratio', 'channel_personeria_creditor_ratio', 'responseCode_personeria_creditor_ratio', 'debtorParticipant_personeria_creditor_ratio', 'Weekday_personeria_creditor_ratio', 'time_interval_personeria_creditor_ratio', 'creditorCCI_personeria_creditor_ratio', 'creditorId_personeria_creditor_ratio', 'personeria_creditor_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "tot_av = ['creditorParticipant_ratio', 'creditorParticipant_currency_ratio', 'creditorParticipant_channel_ratio', 'creditorParticipant_responseCode_ratio', 'creditorParticipant_debtorParticipant_ratio', 'creditorParticipant_Weekday_ratio', 'creditorParticipant_time_interval_ratio', 'creditorParticipant_creditorCCI_ratio', 'currency_ratio', 'currency_channel_ratio', 'currency_responseCode_ratio', 'currency_debtorParticipant_ratio', 'currency_Weekday_ratio', 'currency_time_interval_ratio', 'currency_creditorCCI_ratio', 'channel_ratio', 'channel_responseCode_ratio', 'channel_debtorParticipant_ratio', 'channel_Weekday_ratio', 'channel_time_interval_ratio', 'channel_creditorCCI_ratio', 'responseCode_ratio', 'responseCode_debtorParticipant_ratio', 'responseCode_Weekday_ratio', 'responseCode_time_interval_ratio', 'responseCode_creditorCCI_ratio', 'debtorParticipant_ratio', 'debtorParticipant_Weekday_ratio', 'debtorParticipant_time_interval_ratio', 'debtorParticipant_creditorCCI_ratio', 'Weekday_ratio', 'Weekday_time_interval_ratio', 'Weekday_creditorCCI_ratio', 'time_interval_ratio', 'time_interval_creditorCCI_ratio', 'creditorCCI_ratio', 'hourSin', 'hourCos', 'dayOfYearSin', 'dayOfYearCos', 'dayOfMonthSin', 'dayOfMonthCos', 'dayOfWeekSin', 'dayOfWeekCos', 'debtorParticipant_bcp', 'debtorParticipant_interbank', 'debtorParticipant_citibank', 'debtorParticipant_scotiabank', 'debtorParticipant_bbva', 'debtorParticipant_banco_de_la_nacion', 'debtorParticipant_comercio', 'debtorParticipant_banco_pichincha', 'debtorParticipant_banbif', 'debtorParticipant_crediscotia_financiera', 'debtorParticipant_mi_banco', 'debtorParticipant_gnb', 'debtorParticipant_banco_falabella', 'debtorParticipant_banco_ripley', 'debtorParticipant_alfin_banco_s.a.', 'debtorParticipant_financiera_oh', 'debtorParticipant_financiera_efectiva', 'debtorParticipant_caja_piura', 'debtorParticipant_caja_trujillo', 'debtorParticipant_caja_arequipa', 'debtorParticipant_caja_sullana', 'debtorParticipant_caja_cusco', 'debtorParticipant_caja_huancayo', 'debtorParticipant_caja_ica', 'debtorParticipant_invalid', 'creditorParticipant_bcp', 'creditorParticipant_interbank', 'creditorParticipant_citibank', 'creditorParticipant_scotiabank', 'creditorParticipant_bbva', 'creditorParticipant_banco_de_la_nacion', 'creditorParticipant_comercio', 'creditorParticipant_banco_pichincha', 'creditorParticipant_banbif', 'creditorParticipant_crediscotia_financiera', 'creditorParticipant_mi_banco', 'creditorParticipant_gnb', 'creditorParticipant_banco_falabella', 'creditorParticipant_banco_ripley', 'creditorParticipant_alfin_banco_s.a.', 'creditorParticipant_financiera_oh', 'creditorParticipant_financiera_efectiva', 'creditorParticipant_caja_piura', 'creditorParticipant_caja_trujillo', 'creditorParticipant_caja_arequipa', 'creditorParticipant_caja_sullana', 'creditorParticipant_caja_cusco', 'creditorParticipant_caja_huancayo', 'creditorParticipant_caja_ica', 'creditorParticipant_invalid', 'currency_soles', 'channel_banca_movil', 'channel_invalid', 'channel_web', 'responseCode_rejected', 'f1d', 'f7d', 'f30d', 'f90d', 'f1d_to_creditor', 'f7d_to_creditor', 'f30d_to_creditor', 'f90d_to_creditor', 'unique_debtors_past_1d', 'unique_debtors_past_7d', 'unique_debtors_past_30d', 'unique_debtors_past_90d', 'prop_invalid_1d', 'prop_banca_movil_1d', 'prop_web_1d', 'prop_atm_1d', 'prop_invalid_7d', 'prop_banca_movil_7d', 'prop_web_7d', 'prop_atm_7d', 'prop_invalid_30d', 'prop_banca_movil_30d', 'prop_web_30d', 'prop_atm_30d', 'prop_invalid_90d', 'prop_banca_movil_90d', 'prop_web_90d', 'prop_atm_90d', 'personeria_debtor_natural', 'personeria_creditor_natural', 'fafternoon_1d', 'fmorning_1d', 'fevening_1d', 'fearly morning_1d', 'fafternoon_7d', 'fmorning_7d', 'fevening_7d', 'fearly morning_7d', 'fafternoon_30d', 'fmorning_30d', 'fevening_30d', 'fearly morning_30d', 'fafternoon_90d', 'fmorning_90d', 'fevening_90d', 'fearly morning_90d', 'prop1d_amount', 'prop7d_amount', 'prop30d_amount', 'prop90d_amount', 'transaction_amount', 'creditorParticipant_creditorId_ratio', 'currency_creditorId_ratio', 'channel_creditorId_ratio', 'responseCode_creditorId_ratio', 'debtorParticipant_creditorId_ratio', 'Weekday_creditorId_ratio', 'time_interval_creditorId_ratio', 'creditorCCI_creditorId_ratio', 'creditorId_ratio', 'creditorParticipant_personeria_creditor_ratio', 'currency_personeria_creditor_ratio', 'channel_personeria_creditor_ratio', 'responseCode_personeria_creditor_ratio', 'debtorParticipant_personeria_creditor_ratio', 'Weekday_personeria_creditor_ratio', 'time_interval_personeria_creditor_ratio', 'creditorCCI_personeria_creditor_ratio', 'creditorId_personeria_creditor_ratio', 'personeria_creditor_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def predict_isolation_forest(input_data, model):\n",
    "    print(input_data.columns.tolist())\n",
    "    y_pred = model.predict(input_data)\n",
    "    y_pred = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "    y_pred_series = pd.Series(data=y_pred, index=input_data.index).astype(\"uint8\")\n",
    "    return y_pred_series\n",
    "def score_isolation_forest(input_data, model, days_back):\n",
    "    print(input_data.columns.tolist())\n",
    "    y_pred = model.decision_function(input_data)\n",
    "    print(\"_______________________________\")\n",
    "    print(\"DAYS\", days_back)\n",
    "    print(\"MIN\", y_pred.min())\n",
    "    print(\"MAX\", y_pred.max())\n",
    "    if days_back == 90:\n",
    "        min_value = -0.056870392676392933\n",
    "        max_value = 0.17153726406528225\n",
    "    # norm_y_pred = (y_pred - min_value) / (max_value - min_value) * 99\n",
    "    norm_y_pred = (max_value - y_pred) / (max_value - min_value) * 99\n",
    "    # norm_y_pred = max(0, min(norm_y_pred, 99))\n",
    "    # y_pred = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "    norm_y_pred = norm_y_pred.clip(min=0.0, max=99.0)\n",
    "    # y_pred_series = pd.Series(data=y_pred, index=input_data.index).astype(\"float64\")\n",
    "    y_pred_series = pd.Series(data=norm_y_pred, index=input_data.index).astype(\"float64\")\n",
    "    y_pred_series = y_pred_series.round(8)\n",
    "    return y_pred_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input features: 136\n"
     ]
    }
   ],
   "source": [
    "model_90 = load_model(\"\", \"test_mvp_1_model_90_old_vars_221124.pickle\")\n",
    "print(\"Number of input features:\", model_90.n_features_in_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekday_creditorCCI_ratio\n",
      "Weekday_creditorId_ratio\n",
      "Weekday_ratio\n",
      "Weekday_time_interval_ratio\n",
      "channel_Weekday_ratio\n",
      "channel_banca_movil\n",
      "channel_creditorCCI_ratio\n",
      "channel_creditorId_ratio\n",
      "channel_debtorParticipant_ratio\n",
      "channel_invalid\n",
      "channel_ratio\n",
      "channel_responseCode_ratio\n",
      "channel_time_interval_ratio\n",
      "channel_web\n",
      "creditorCCI_creditorId_ratio\n",
      "creditorCCI_ratio\n",
      "creditorId_ratio\n",
      "creditorParticipant_Weekday_ratio\n",
      "creditorParticipant_alfin_banco_s.a.\n",
      "creditorParticipant_banbif\n",
      "creditorParticipant_banco_de_la_nacion\n",
      "creditorParticipant_banco_falabella\n",
      "creditorParticipant_banco_pichincha\n",
      "creditorParticipant_banco_ripley\n",
      "creditorParticipant_bbva\n",
      "creditorParticipant_bcp\n",
      "creditorParticipant_caja_arequipa\n",
      "creditorParticipant_caja_cusco\n",
      "creditorParticipant_caja_huancayo\n",
      "creditorParticipant_caja_ica\n",
      "creditorParticipant_caja_piura\n",
      "creditorParticipant_caja_sullana\n",
      "creditorParticipant_caja_trujillo\n",
      "creditorParticipant_channel_ratio\n",
      "creditorParticipant_citibank\n",
      "creditorParticipant_comercio\n",
      "creditorParticipant_crediscotia_financiera\n",
      "creditorParticipant_creditorCCI_ratio\n",
      "creditorParticipant_creditorId_ratio\n",
      "creditorParticipant_currency_ratio\n",
      "creditorParticipant_debtorParticipant_ratio\n",
      "creditorParticipant_financiera_efectiva\n",
      "creditorParticipant_financiera_oh\n",
      "creditorParticipant_gnb\n",
      "creditorParticipant_interbank\n",
      "creditorParticipant_invalid\n",
      "creditorParticipant_mi_banco\n",
      "creditorParticipant_ratio\n",
      "creditorParticipant_responseCode_ratio\n",
      "creditorParticipant_scotiabank\n",
      "creditorParticipant_time_interval_ratio\n",
      "currency_Weekday_ratio\n",
      "currency_channel_ratio\n",
      "currency_creditorCCI_ratio\n",
      "currency_creditorId_ratio\n",
      "currency_debtorParticipant_ratio\n",
      "currency_ratio\n",
      "currency_responseCode_ratio\n",
      "currency_soles\n",
      "currency_time_interval_ratio\n",
      "dayOfMonthCos\n",
      "dayOfMonthSin\n",
      "dayOfWeekCos\n",
      "dayOfWeekSin\n",
      "dayOfYearCos\n",
      "dayOfYearSin\n",
      "debtorParticipant_Weekday_ratio\n",
      "debtorParticipant_alfin_banco_s.a.\n",
      "debtorParticipant_banbif\n",
      "debtorParticipant_banco_de_la_nacion\n",
      "debtorParticipant_banco_falabella\n",
      "debtorParticipant_banco_pichincha\n",
      "debtorParticipant_banco_ripley\n",
      "debtorParticipant_bbva\n",
      "debtorParticipant_bcp\n",
      "debtorParticipant_caja_arequipa\n",
      "debtorParticipant_caja_cusco\n",
      "debtorParticipant_caja_huancayo\n",
      "debtorParticipant_caja_ica\n",
      "debtorParticipant_caja_piura\n",
      "debtorParticipant_caja_sullana\n",
      "debtorParticipant_caja_trujillo\n",
      "debtorParticipant_citibank\n",
      "debtorParticipant_comercio\n",
      "debtorParticipant_crediscotia_financiera\n",
      "debtorParticipant_creditorCCI_ratio\n",
      "debtorParticipant_creditorId_ratio\n",
      "debtorParticipant_financiera_efectiva\n",
      "debtorParticipant_financiera_oh\n",
      "debtorParticipant_gnb\n",
      "debtorParticipant_interbank\n",
      "debtorParticipant_invalid\n",
      "debtorParticipant_mi_banco\n",
      "debtorParticipant_ratio\n",
      "debtorParticipant_scotiabank\n",
      "debtorParticipant_time_interval_ratio\n",
      "f1d\n",
      "f1d_to_creditor\n",
      "f30d\n",
      "f30d_to_creditor\n",
      "f7d\n",
      "f7d_to_creditor\n",
      "f90d\n",
      "f90d_to_creditor\n",
      "hourCos\n",
      "hourSin\n",
      "prop_atm_1d\n",
      "prop_atm_30d\n",
      "prop_atm_7d\n",
      "prop_atm_90d\n",
      "prop_banca_movil_1d\n",
      "prop_banca_movil_30d\n",
      "prop_banca_movil_7d\n",
      "prop_banca_movil_90d\n",
      "prop_invalid_1d\n",
      "prop_invalid_30d\n",
      "prop_invalid_7d\n",
      "prop_invalid_90d\n",
      "prop_web_1d\n",
      "prop_web_30d\n",
      "prop_web_7d\n",
      "prop_web_90d\n",
      "responseCode_Weekday_ratio\n",
      "responseCode_creditorCCI_ratio\n",
      "responseCode_creditorId_ratio\n",
      "responseCode_debtorParticipant_ratio\n",
      "responseCode_ratio\n",
      "responseCode_rejected\n",
      "responseCode_time_interval_ratio\n",
      "time_interval_creditorCCI_ratio\n",
      "time_interval_creditorId_ratio\n",
      "time_interval_ratio\n",
      "unique_debtors_past_1d\n",
      "unique_debtors_past_30d\n",
      "unique_debtors_past_7d\n",
      "unique_debtors_past_90d\n"
     ]
    }
   ],
   "source": [
    "for x in model_90.feature_names_in_:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input features: 136\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of input features:\", model_90.n_features_in_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "y_pred_90 = predict_isolation_forest(AV_90.drop(id_cols, axis=1), model_90)\n",
    "y_pred_90_same = pd.Series(data=[0] * len(final_same), index=final_same.index).astype(\"uint8\")\n",
    "y_pred_90 = pd.concat([y_pred_90, y_pred_90_same], axis=0)\n",
    "\n",
    "y_score_90 = score_isolation_forest(AV_90.drop(id_cols, axis=1), model_90, 90)\n",
    "y_score_90_same = pd.Series(data=[0] * len(final_same), index=final_same.index).astype(\"float64\")\n",
    "y_score_90 = pd.concat([y_score_90, y_score_90_same], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "new_columns = [\n",
    "    'f1d',\n",
    "    'f7d',\n",
    "    'f30d',\n",
    "    'f90d',\n",
    "    'f1d_to_creditor',\n",
    "    'f7d_to_creditor',\n",
    "    'f30d_to_creditor',\n",
    "    'f90d_to_creditor',\n",
    "    'unique_debtors_past_1d',\n",
    "    'unique_debtors_past_7d',\n",
    "    'unique_debtors_past_30d',\n",
    "    'unique_debtors_past_90d',\n",
    "    'prop_invalid_1d',\n",
    "    'prop_banca_movil_1d',\n",
    "    'prop_web_1d',\n",
    "    'prop_atm_1d',\n",
    "    'prop_invalid_7d',\n",
    "    'prop_banca_movil_7d',\n",
    "    'prop_web_7d',\n",
    "    'prop_atm_7d',\n",
    "    'prop_invalid_30d',\n",
    "    'prop_banca_movil_30d',\n",
    "    'prop_web_30d',\n",
    "    'prop_atm_30d',\n",
    "    'prop_invalid_90d',\n",
    "    'prop_banca_movil_90d',\n",
    "    'prop_web_90d',\n",
    "    'prop_atm_90d',\n",
    "]\n",
    "new_ratios = [\n",
    "    \"creditorParticipant_creditorId_ratio\",\n",
    "    \"currency_creditorId_ratio\",\n",
    "    \"channel_creditorId_ratio\",\n",
    "    \"responseCode_creditorId_ratio\",\n",
    "    \"debtorParticipant_creditorId_ratio\",\n",
    "    \"Weekday_creditorId_ratio\",\n",
    "    \"time_interval_creditorId_ratio\",\n",
    "    \"creditorCCI_creditorId_ratio\",\n",
    "    \"creditorId_ratio\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "id_descriptive_features_list = \\\n",
    "    ['pk', 'debtorId', 'creditorCCI', 'creditorId', 'creditorIdCode', 'message_id', 'trace', 'instruction_id', 'run_id',\n",
    "    'creationDate', 'creationTime', 'channel', 'currency', 'creditorParticipant', 'debtorParticipant',\n",
    "    'debtorTypeOfPerson', 'transactionType', 'debtorIdCode', 'reasonCode', 'responseCode', 'same_customer_flag']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "original_values_set = AV_consolidado_original_values_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "rate_features_list_90_new = AV_90.filter(like=\"_ratio\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "rate_features_list_90_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "AV_90.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "pd.concat([AV_90, final_same], axis=0).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "original_values_set[id_descriptive_features_list]\\\n",
    "            .merge(pd.concat([AV_90, final_same], axis=0)[rate_features_list_90_new], how=\"inner\", left_index=True, right_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
